{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### astuce sirine ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sort(f.col('networkid').desc(), f.col('softwareVersion').desc())\n",
    "df_fin = df2.dropDuplicates(subset = ['networkid'])\n",
    "\n",
    "df_agg_nombre = df_agg_nombre.withColumn('band',f.lit(\"0\"))\n",
    "\n",
    "df_netw_band_agg_tot.write.mode('append').format('parquet').partitionBy(\"day\", \"data_type\").saveAsTable('req_stc.ecms_metrics_agg_day_network_kpi')\n",
    " \n",
    "df_rssi_agg_tot_count = df_rssi_agg_tot_count.withColumn('percent', (f.round((f.col('nombre_client')/f.col('sum(nombre_client)')),4)))\n",
    "    \n",
    "df_household = df_household.withColumn(\"date\" , f.from_unixtime(f.col(\"time\") , \"yyyy-MM-dd HH:mm:ss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sauvegarde dans une table \n",
    "df_tot.write.mode('append').format('parquet').partitionBy(\"day\", \"data_type\").saveAsTable('req_stc.ecms_metrics_network_day')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### récupération automatique des données ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date \n",
    "df_ini = spark.read.parquet(\"/warehouse/tablespace/external/hive/req_stc.db/ssa_ecms_kpi_nombre_day_eole\") ## max de la table de suavegarde finale\n",
    "\n",
    "max_day = df_ini.agg(f.max('day')).toPandas().iloc[0][0]\n",
    "day_ref = (date.today()-max_day).days-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ecms   = spark.read.parquet(\"/warehouse/tablespace/external/hive/req_stc.db/ecms_household_day_rc2_v2\").filter(f.col('day') >= f.date_sub(f.current_date(),day_ref+1))\n",
    "src_metrics   = spark.read.parquet(\"/warehouse/tablespace/external/hive/req_stc.db/ecms_metrics_network_day\").filter(f.col('day') >= f.date_sub(f.current_date(),day_ref+1))\n",
    "\n",
    "src_ecms_dmax = src_ecms.agg(f.max('day')).toPandas().iloc[0][0]\n",
    "src_metrics_dmax = src_metrics.filter(f.col('data_type')==0).agg(f.max('day')).toPandas().iloc[0][0]\n",
    "\n",
    "min_day = min([src_ecms_dmax\n",
    "               ,src_metrics_dmax\n",
    "               ]) \n",
    " \n",
    "day_j = (date.today()-min_day).days\n",
    "\n",
    "day_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while  day_ref >=  day_j :    \n",
    "    \n",
    "\n",
    "        ########### calcul nombre de clients à partir de la base de données customer base ############\n",
    "    df = src_ecms.filter(src_ecms.day == f.date_sub(f.current_date(),day_ref)\n",
    "                                    ).select('day','networkid').filter(src_ecms.networkid.like('127%')).distinct()\n",
    "                                    \n",
    "    day_ref = day_ref - 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### window ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy('day_UTFR', 'networkid', 'childID'\n",
    "          ).orderBy(f.col('last_sn').asc())\n",
    "\n",
    "\n",
    "data_2_4 = data_2_4.withColumn(\"cnx_ID_avant\",f.lag(\"connectionId\",1).over(windowSpec))\n",
    "data_2_4 = data_2_4.withColumn(\"lag_time\",f.lag(\"last_sn\",1).over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = df_tot[['day', 'networkid', 'band', 'data_type', 'data_type_value', 'data_type_interval']]\n",
    "\n",
    "w = Window.partitionBy('day', 'networkid')\n",
    "\n",
    "df_tot = df_tot.withColumn('data_type_interval_tot', f.max('data_type_interval').over(w)\n",
    "                                ).withColumn('data_type_value_max', f.max('data_type_value').over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_window = Window.partitionBy('networkid')\n",
    "magic_percentile = f.expr('percentile_approx(data_type_interval_int, 0.5)')\n",
    "\n",
    "df_tot_count_filtred = df_tot_count_filtred.withColumn('med_val', magic_percentile.over(grp_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy('day_UTFR', 'networkid', 'childID'\n",
    "          ).orderBy(f.col('last_sn').asc())\n",
    "\n",
    "\n",
    "data_2_4 = data_2_4.withColumn(\"cnx_ID_avant\",f.lag(\"connectionId\",1).over(windowSpec))\n",
    "data_2_4 = data_2_4.withColumn(\"lag_time\",f.lag(\"last_sn\",1).over(windowSpec))\n",
    "data_2_4 = data_2_4.withColumn(\"trafic_avant\",f.lag(\"max_trafic\",1).over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = Window.partitionBy('day_UTFR', 'networkid', 'childID', 'connectionId', 'band'\n",
    "      ).orderBy(f.col('time').asc()).rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "df_donne_tot = df_donne_tot.withColumn (\"last_sn\", f.last('UTCFRA', True).over(wd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def date_range(start, end):\n",
    "    delta = end - start  # as timedelta\n",
    "    days = [(start + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(delta.days + 1)]\n",
    "    return days\n",
    "\n",
    "\n",
    "start_date_1 = datetime(2022, 2, 3)\n",
    "end_date_1 = datetime(2022,2, 5)\n",
    "    \n",
    "days_1= date_range(start_date_1, end_date_1)\n",
    "\n",
    "liste_dates = [*days_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statique = df_statique.withColumn('day', f.from_unixtime(f.unix_timestamp('date', 'dd/MM/yyyy'))) convert timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### concaténer plusieurs éléments  ###\n",
    "\n",
    "df_channel_band_5.groupby(\"IMEI\").agg(f.concat_ws(\", \", f.collect_list(df_channel_band_5.day_5)).alias('day_5'),\n",
    "                                            f.concat_ws(\", \", f.first(df_channel_band_5.lag_wifi_5_canal_auto), f.collect_list(df_channel_band_5.wifi_5_canal_auto)).alias('wifi_5_canal_auto'))\n",
    "                                            \n",
    "                                            \n",
    "|           IMEI|                 day|wifi_2_4_canal_auto|channel_enabled_2_4|      networkid|               day_5|wifi_5_canal_auto|channel_enabled_5|\n",
    "+---------------+--------------------+-------------------+-------------------+---------------+--------------------+-----------------+-----------------+\n",
    "|127213037308043|2021-09-25 00:00:...|       Yes, No, Yes|           statique|127213037308043|2021-09-25 00:00:...|     Yes, No, Yes|         statique|\n",
    "|127213109613320|2021-09-15 00:00:...|       Yes, No, Yes|           statique|127213109613320|2021-09-15 00:00:...|     Yes, No, Yes|         statique|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###converison seconde en heures minutes secondes\n",
    "\n",
    "from time import *\n",
    "print(strftime('%H %M %S', gmtime(52890)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iad_nbr_rep = iad_nbr_rep.withColumn(\"nbr_rep\", \\\n",
    "                      f.when(iad_nbr_rep[\"nbr_rep_2\"] >2 , 2).otherwise(iad_nbr_rep[\"nbr_rep_2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show partitions req_stc.ecms_metrics_network_day\").show(1500)  #####partion des données\n",
    "#import shutil\n",
    "#spark.read.parquet('/warehouse/tablespace/external/hive/c/ecms_metrics_network_day/day=2021-03-17/data_type=0').count()\n",
    "#/warehouse/tablespace/external/hive/msf_exploratoire.db/dng_fai_client_parquet\n",
    "#shutil.rmtree('/warehouse/tablespace/external/hive/c/ecms_metrics_network_day/day=2021-03-17/data_type=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pour modifier une partition bien précise il faut que les colonnes soit dans le méme ordre ###\n",
    "\n",
    "df.createOrReplaceTempView(\"temp_view\")\n",
    "\n",
    "spark.sql(\"insert overwrite table req_stc_dev.ecms_test_mise_a_jour partition (day= '2022-01-22') select data_type,data_type_name,data_type_interval, data_type_interval_name, firstname    from temp_view\")\n",
    "\n",
    "### a on fait withColumn pour changer la valeur de la colonne et on met ###\n",
    "\n",
    "df.write.mode('Overwrite').save(\"/warehouse/tablespace/external/hive/req_stc_dev.db/ecms_test_mise_a_jour/day=2022-01-22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###converison seconde en heures minutes secondes\n",
    "\n",
    "from time import *\n",
    "print(strftime('%H %M %S', gmtime(540017)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### exemple airflow avec plusieurs scripts ###\n",
    "\n",
    "from airflow import DAG\n",
    "from datetime import datetime, timedelta\n",
    "from airflow.contrib.operators.kubernetes_pod_operator import KubernetesPodOperator\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "\n",
    "from airflow.operators.email_operator import EmailOperator\n",
    "from airflow.models import Variable\n",
    "from airflow.utils.trigger_rule import TriggerRule\n",
    "\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'alghali',\n",
    "    'depends_on_past': False,  \n",
    "    'email': ['ALGHALI@bouyguestelecom.fr'],\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=1)\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'dpps_cqf_agh_TVoverWIFI', \n",
    "    default_args=default_args, \n",
    "    start_date=datetime.strptime(\"2022-01-20\", \"%Y-%M-%d\"),\n",
    "    schedule_interval=\"0 09 * * *\",\n",
    "    catchup=False)\n",
    "\n",
    "\n",
    "start = DummyOperator(\n",
    "    task_id='start',\n",
    "    dag=dag)\n",
    "\n",
    "\n",
    "end = DummyOperator(\n",
    "    task_id='end',\n",
    "    dag=dag)\n",
    "\n",
    "\n",
    "DPPS_CQF_YYI_IoW_NGR1 = KubernetesPodOperator(namespace='airflow-prod',\n",
    "                          image=\"bt1svpm0.bpa.bouyguestelecom.fr:8084/release/airflow/notebooks:prod\",\n",
    "                          is_delete_operator_pod=True,\n",
    "                          arguments=[\"notebooks_dpps/DPPS_CQF_YYI_IoW_NGR1.ipynb\",\"-u\",\"dpps\", \"--timeout\", \"86000\"],\n",
    "                          name=\"DPPS_CQF_YYI_IoW_NGR1\",\n",
    "                          task_id=\"DPPS_CQF_YYI_IoW_NGR1\",\n",
    "                          image_pull_policy='Always',\n",
    "                          get_logs=False,\n",
    "                          service_account_name=\"airflow\",\n",
    "                          dag=dag\n",
    "                          )\n",
    "\n",
    "dpps_cqf_ssa_ToW_vanc_eole_1 = KubernetesPodOperator(namespace='airflow-prod',\n",
    "                          image=\"bt1svpm0.bpa.bouyguestelecom.fr:8084/release/airflow/notebooks:prod\",\n",
    "                          is_delete_operator_pod=True,\n",
    "                          arguments=[\"notebooks_dpps/dpps_cqf_ssa_ToW_vanc_eole_1.ipynb\",\"-u\",\"dpps\", \"--timeout\", \"86000\"],\n",
    "                          name=\"dpps_cqf_ssa_ToW_vanc_eole_1\",\n",
    "                          task_id=\"dpps_cqf_ssa_ToW_vanc_eole_1\",\n",
    "                          image_pull_policy='Always',\n",
    "                          get_logs=False,\n",
    "                          service_account_name=\"airflow\",\n",
    "                          dag=dag\n",
    "                          )\n",
    "\n",
    "dpps_cqf_agh_ToW_vanc_eole_2 = KubernetesPodOperator(namespace='airflow-prod',\n",
    "                          image=\"bt1svpm0.bpa.bouyguestelecom.fr:8084/release/airflow/notebooks:prod\",\n",
    "                          is_delete_operator_pod=True,\n",
    "                          arguments=[\"notebooks_dpps/dpps_cqf_agh_ToW_vanc_eole_2.ipynb\",\"-u\",\"dpps\", \"--timeout\", \"86000\"],\n",
    "                          name=\"dpps_cqf_agh_ToW_vanc_eole_2\",\n",
    "                          task_id=\"dpps_cqf_agh_ToW_vanc_eole_2\",\n",
    "                          image_pull_policy='Always',\n",
    "                          get_logs=False,\n",
    "                          service_account_name=\"airflow\",\n",
    "                          dag=dag\n",
    "                          )\n",
    "\n",
    "\n",
    "AllTaskSuccess = EmailOperator (\n",
    "    dag=dag,\n",
    "    trigger_rule=TriggerRule.ALL_SUCCESS,\n",
    "    task_id=\"AllTaskSuccess\",\n",
    "    to=[\"ALGHALI@bouyguestelecom.fr\"],\n",
    "    subject=\"Dag TVoWIFI completed successfully\",\n",
    "    html_content='<h5>Hello Alaeddine,<br><br>TV over WIFI dag completed </h5><h4><font color=\"green\">successfully.</font></h4><br><br><h5>Regards</h5>')\n",
    "\n",
    "\n",
    "Task_Failed = EmailOperator (\n",
    "    dag=dag,\n",
    "    trigger_rule=TriggerRule.ONE_FAILED,\n",
    "    task_id=\"Task_Failed\",\n",
    "    to=[\"ALGHALI@bouyguestelecom.fr\"],\n",
    "    subject=\"TVoWIFI Task Failed\",\n",
    "    html_content='<h3>Task Failed</h3>')\n",
    "\n",
    "start >> [DPPS_CQF_YYI_IoW_NGR1, dpps_cqf_ssa_ToW_vanc_eole_1] \n",
    "dpps_cqf_ssa_ToW_vanc_eole_1 >> dpps_cqf_agh_ToW_vanc_eole_2\n",
    "[DPPS_CQF_YYI_IoW_NGR1, dpps_cqf_ssa_ToW_vanc_eole_1, dpps_cqf_agh_ToW_vanc_eole_2] >> Task_Failed \n",
    "[DPPS_CQF_YYI_IoW_NGR1, dpps_cqf_agh_ToW_vanc_eole_2] >> AllTaskSuccess >> end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
